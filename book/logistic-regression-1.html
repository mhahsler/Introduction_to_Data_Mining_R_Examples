<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 9 Logistic Regression* | An R Companion for Introduction to Data Mining</title>
<meta name="author" content="Michael Hahsler">
<meta name="description" content="This chapter introduces the popular classification method logistic regression. Packages Used in this Chapter This chapter only uses R’s base functionality and does not need extra packages.  9.1...">
<meta name="generator" content="bookdown 0.40 with bs4_book()">
<meta property="og:title" content="Chapter 9 Logistic Regression* | An R Companion for Introduction to Data Mining">
<meta property="og:type" content="book">
<meta property="og:image" content="/images/cover.png">
<meta property="og:description" content="This chapter introduces the popular classification method logistic regression. Packages Used in this Chapter This chapter only uses R’s base functionality and does not need extra packages.  9.1...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 9 Logistic Regression* | An R Companion for Introduction to Data Mining">
<meta name="twitter:description" content="This chapter introduces the popular classification method logistic regression. Packages Used in this Chapter This chapter only uses R’s base functionality and does not need extra packages.  9.1...">
<meta name="twitter:image" content="/images/cover.png">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap/bootstrap.bundle.min.js"></script><script src="libs/bs3compat/transition.js"></script><script src="libs/bs3compat/tabs.js"></script><script src="libs/bs3compat/bs3compat.js"></script><link href="libs/bs4_book/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book/bs4_book.js"></script><link href="libs/htmltools-fill/fill.css" rel="stylesheet">
<script src="libs/htmlwidgets/htmlwidgets.js"></script><script src="libs/plotly-binding/plotly.js"></script><script src="libs/typedarray/typedarray.min.js"></script><link href="libs/crosstalk/css/crosstalk.min.css" rel="stylesheet">
<script src="libs/crosstalk/js/crosstalk.min.js"></script><link href="libs/plotly-htmlwidgets-css/plotly-htmlwidgets.css" rel="stylesheet">
<script src="libs/plotly-main/plotly-latest.min.js"></script><link href="libs/datatables-css/datatables-crosstalk.css" rel="stylesheet">
<script src="libs/datatables-binding/datatables.js"></script><link href="libs/dt-core/css/jquery.dataTables.min.css" rel="stylesheet">
<link href="libs/dt-core/css/jquery.dataTables.extra.css" rel="stylesheet">
<script src="libs/dt-core/js/jquery.dataTables.min.js"></script><link href="libs/nouislider/jquery.nouislider.min.css" rel="stylesheet">
<script src="libs/nouislider/jquery.nouislider.min.js"></script><link href="libs/selectize/selectize.bootstrap3.css" rel="stylesheet">
<script src="libs/selectize/selectize.min.js"></script><link href="libs/vis/vis-network.min.css" rel="stylesheet">
<script src="libs/vis/vis-network.min.js"></script><script src="libs/visNetwork-binding/visNetwork.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">An R Companion for Introduction to Data Mining</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Preface</a></li>
<li><a class="" href="introduction.html"><span class="header-section-number">1</span> Introduction</a></li>
<li><a class="" href="data.html"><span class="header-section-number">2</span> Data</a></li>
<li><a class="" href="classification-basic-concepts.html"><span class="header-section-number">3</span> Classification: Basic Concepts</a></li>
<li><a class="" href="classification-alternative-techniques.html"><span class="header-section-number">4</span> Classification: Alternative Techniques</a></li>
<li><a class="" href="association-analysis-basic-concepts.html"><span class="header-section-number">5</span> Association Analysis: Basic Concepts</a></li>
<li><a class="" href="association-analysis-advanced-concepts.html"><span class="header-section-number">6</span> Association Analysis: Advanced Concepts</a></li>
<li><a class="" href="cluster-analysis.html"><span class="header-section-number">7</span> Cluster Analysis</a></li>
<li><a class="" href="regression.html"><span class="header-section-number">8</span> Regression*</a></li>
<li><a class="active" href="logistic-regression-1.html"><span class="header-section-number">9</span> Logistic Regression*</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/mhahsler/Introduction_to_Data_Mining_R_Examples">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="logistic-regression-1" class="section level1" number="9">
<h1>
<span class="header-section-number">9</span> Logistic Regression*<a class="anchor" aria-label="anchor" href="#logistic-regression-1"><i class="fas fa-link"></i></a>
</h1>
<p>This chapter introduces the popular classification method
logistic regression.</p>
<div id="packages-used-in-this-chapter-7" class="section level3 unnumbered">
<h3>Packages Used in this Chapter<a class="anchor" aria-label="anchor" href="#packages-used-in-this-chapter-7"><i class="fas fa-link"></i></a>
</h3>
<p>This chapter only uses R’s base functionality and does not need extra packages.</p>
</div>
<div id="introduction-2" class="section level2" number="9.1">
<h2>
<span class="header-section-number">9.1</span> Introduction<a class="anchor" aria-label="anchor" href="#introduction-2"><i class="fas fa-link"></i></a>
</h2>
<p>Logistic regression contains the word regression, but it is actually a
probabilistic statistical classification
model to predict a binary outcome (a probability) given a set of features.
It is a very powerful model that can be fit very quickly. It is one of the
first classification models you should try on new data.</p>
<p>Logistic regression can be thought of as a linear regression with the
log odds ratio (logit)
of the binary outcome as the dependent variable:</p>
<p><span class="math display">\[logit(p) = ln(\frac{p}{1-p}) = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ...\]</span></p>
<div class="sourceCode" id="cb475"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">logit</span>  <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">p</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">p</span><span class="op">/</span><span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="va">p</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">x</span>, <span class="fu">logit</span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, type <span class="op">=</span> <span class="st">"l"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>v<span class="op">=</span><span class="fl">0.5</span>, lty <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>h<span class="op">=</span><span class="fl">0</span>, lty <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="R-Companion-Data-Mining_files/figure-html/unnamed-chunk-428-1.png" width="672"></div>
<p>This is equivalent to modeling the probability of the outcome <span class="math inline">\(p\)</span> by</p>
<p><span class="math display">\[ p = \frac{e^{\beta_0 + \beta_1 x_1 + \beta_2 x_2 + ...}}{1 +  e^{\beta_0 + \beta_1 x_1 + \beta_2 x_2 + ...}} = \frac{1}{1+e^{-(\beta_0 + \beta_1 x_1 + \beta_2 x_2 + ...)}}\]</span></p>
</div>
<div id="data-preparation-1" class="section level2" number="9.2">
<h2>
<span class="header-section-number">9.2</span> Data Preparation<a class="anchor" aria-label="anchor" href="#data-preparation-1"><i class="fas fa-link"></i></a>
</h2>
<p>Load and shuffle data. We also add a useless variable to see if the logistic regression removes it.</p>
<div class="sourceCode" id="cb476"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">iris</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">100</span><span class="op">)</span> <span class="co"># for reproducability</span></span>
<span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="va">iris</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/pkg/arules/man/sample.html">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">iris</span><span class="op">)</span><span class="op">)</span>,<span class="op">]</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">x</span>, useless <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>Make Species into a binary classification problem so we will
classify if a flower is of species Virginica</p>
<div class="sourceCode" id="cb477"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">x</span><span class="op">$</span><span class="va">virginica</span> <span class="op">&lt;-</span> <span class="va">x</span><span class="op">$</span><span class="va">Species</span> <span class="op">==</span> <span class="st">"virginica"</span></span>
<span><span class="va">x</span><span class="op">$</span><span class="va">Species</span> <span class="op">&lt;-</span> <span class="cn">NULL</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">x</span>, col<span class="op">=</span><span class="va">x</span><span class="op">$</span><span class="va">virginica</span><span class="op">+</span><span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="R-Companion-Data-Mining_files/figure-html/unnamed-chunk-430-1.png" width="672"></div>
</div>
<div id="create-a-logistic-regression-model" class="section level2" number="9.3">
<h2>
<span class="header-section-number">9.3</span> Create a Logistic Regression Model<a class="anchor" aria-label="anchor" href="#create-a-logistic-regression-model"><i class="fas fa-link"></i></a>
</h2>
<p>Logistic regression is a generalized linear model (GLM) with logit as the
link function and a binomial error model.</p>
<div class="sourceCode" id="cb478"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">virginica</span> <span class="op">~</span> <span class="va">.</span>,</span>
<span>  family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">binomial</a></span><span class="op">(</span><span class="va">logit</span><span class="op">)</span>, data<span class="op">=</span><span class="va">x</span><span class="op">)</span></span>
<span><span class="co">## Warning: glm.fit: fitted probabilities numerically 0 or 1</span></span>
<span><span class="co">## occurred</span></span></code></pre></div>
<p>About the warning: glm.fit: fitted probabilities numerically 0 or 1 occurred means that the data is possibly linearly separable.</p>
<div class="sourceCode" id="cb479"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Call:  glm(formula = virginica ~ ., family = binomial(logit), data = x)</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Coefficients:</span></span>
<span><span class="co">##  (Intercept)  Sepal.Length   Sepal.Width  Petal.Length  </span></span>
<span><span class="co">##      -41.649        -2.531        -6.448         9.376  </span></span>
<span><span class="co">##  Petal.Width       useless  </span></span>
<span><span class="co">##       17.696         0.098  </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Degrees of Freedom: 149 Total (i.e. Null);  144 Residual</span></span>
<span><span class="co">## Null Deviance:       191 </span></span>
<span><span class="co">## Residual Deviance: 11.9  AIC: 23.9</span></span></code></pre></div>
<p>Check which features are significant?</p>
<div class="sourceCode" id="cb480"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">model</span><span class="op">)</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Call:</span></span>
<span><span class="co">## glm(formula = virginica ~ ., family = binomial(logit), data = x)</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Coefficients:</span></span>
<span><span class="co">##              Estimate Std. Error z value Pr(&gt;|z|)  </span></span>
<span><span class="co">## (Intercept)   -41.649     26.556   -1.57    0.117  </span></span>
<span><span class="co">## Sepal.Length   -2.531      2.458   -1.03    0.303  </span></span>
<span><span class="co">## Sepal.Width    -6.448      4.794   -1.34    0.179  </span></span>
<span><span class="co">## Petal.Length    9.376      4.763    1.97    0.049 *</span></span>
<span><span class="co">## Petal.Width    17.696     10.632    1.66    0.096 .</span></span>
<span><span class="co">## useless         0.098      0.807    0.12    0.903  </span></span>
<span><span class="co">## ---</span></span>
<span><span class="co">## Signif. codes:  </span></span>
<span><span class="co">## 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## (Dispersion parameter for binomial family taken to be 1)</span></span>
<span><span class="co">## </span></span>
<span><span class="co">##     Null deviance: 190.954  on 149  degrees of freedom</span></span>
<span><span class="co">## Residual deviance:  11.884  on 144  degrees of freedom</span></span>
<span><span class="co">## AIC: 23.88</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Number of Fisher Scoring iterations: 12</span></span></code></pre></div>
<p>AIC can be used for model selection</p>
</div>
<div id="stepwise-variable-selection-1" class="section level2" number="9.4">
<h2>
<span class="header-section-number">9.4</span> Stepwise Variable Selection<a class="anchor" aria-label="anchor" href="#stepwise-variable-selection-1"><i class="fas fa-link"></i></a>
</h2>
<div class="sourceCode" id="cb481"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/step.html">step</a></span><span class="op">(</span><span class="va">model</span>, data <span class="op">=</span> <span class="va">x</span><span class="op">)</span></span>
<span><span class="co">## Start:  AIC=23.88</span></span>
<span><span class="co">## virginica ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width + </span></span>
<span><span class="co">##     useless</span></span>
<span><span class="co">## Warning: glm.fit: fitted probabilities numerically 0 or 1</span></span>
<span><span class="co">## occurred</span></span>
<span><span class="co">## Warning: glm.fit: fitted probabilities numerically 0 or 1</span></span>
<span><span class="co">## occurred</span></span>
<span><span class="co">## Warning: glm.fit: fitted probabilities numerically 0 or 1</span></span>
<span><span class="co">## occurred</span></span>
<span><span class="co">## Warning: glm.fit: fitted probabilities numerically 0 or 1</span></span>
<span><span class="co">## occurred</span></span>
<span><span class="co">## Warning: glm.fit: fitted probabilities numerically 0 or 1</span></span>
<span><span class="co">## occurred</span></span>
<span><span class="co">##                Df Deviance  AIC</span></span>
<span><span class="co">## - useless       1     11.9 21.9</span></span>
<span><span class="co">## - Sepal.Length  1     13.2 23.2</span></span>
<span><span class="co">## &lt;none&gt;                11.9 23.9</span></span>
<span><span class="co">## - Sepal.Width   1     14.8 24.8</span></span>
<span><span class="co">## - Petal.Width   1     22.4 32.4</span></span>
<span><span class="co">## - Petal.Length  1     25.9 35.9</span></span>
<span><span class="co">## Warning: glm.fit: fitted probabilities numerically 0 or 1</span></span>
<span><span class="co">## occurred</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Step:  AIC=21.9</span></span>
<span><span class="co">## virginica ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width</span></span>
<span><span class="co">## Warning: glm.fit: fitted probabilities numerically 0 or 1</span></span>
<span><span class="co">## occurred</span></span>
<span><span class="co">## Warning: glm.fit: fitted probabilities numerically 0 or 1</span></span>
<span><span class="co">## occurred</span></span>
<span><span class="co">## Warning: glm.fit: fitted probabilities numerically 0 or 1</span></span>
<span><span class="co">## occurred</span></span>
<span><span class="co">## Warning: glm.fit: fitted probabilities numerically 0 or 1</span></span>
<span><span class="co">## occurred</span></span>
<span><span class="co">##                Df Deviance  AIC</span></span>
<span><span class="co">## - Sepal.Length  1     13.3 21.3</span></span>
<span><span class="co">## &lt;none&gt;                11.9 21.9</span></span>
<span><span class="co">## - Sepal.Width   1     15.5 23.5</span></span>
<span><span class="co">## - Petal.Width   1     23.8 31.8</span></span>
<span><span class="co">## - Petal.Length  1     25.9 33.9</span></span>
<span><span class="co">## Warning: glm.fit: fitted probabilities numerically 0 or 1</span></span>
<span><span class="co">## occurred</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Step:  AIC=21.27</span></span>
<span><span class="co">## virginica ~ Sepal.Width + Petal.Length + Petal.Width</span></span>
<span><span class="co">## Warning: glm.fit: fitted probabilities numerically 0 or 1</span></span>
<span><span class="co">## occurred</span></span>
<span><span class="co">## Warning: glm.fit: fitted probabilities numerically 0 or 1</span></span>
<span><span class="co">## occurred</span></span>
<span><span class="co">##                Df Deviance  AIC</span></span>
<span><span class="co">## &lt;none&gt;                13.3 21.3</span></span>
<span><span class="co">## - Sepal.Width   1     20.6 26.6</span></span>
<span><span class="co">## - Petal.Length  1     27.4 33.4</span></span>
<span><span class="co">## - Petal.Width   1     31.5 37.5</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">model2</span><span class="op">)</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Call:</span></span>
<span><span class="co">## glm(formula = virginica ~ Sepal.Width + Petal.Length + Petal.Width, </span></span>
<span><span class="co">##     family = binomial(logit), data = x)</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Coefficients:</span></span>
<span><span class="co">##              Estimate Std. Error z value Pr(&gt;|z|)  </span></span>
<span><span class="co">## (Intercept)    -50.53      23.99   -2.11    0.035 *</span></span>
<span><span class="co">## Sepal.Width     -8.38       4.76   -1.76    0.079 .</span></span>
<span><span class="co">## Petal.Length     7.87       3.84    2.05    0.040 *</span></span>
<span><span class="co">## Petal.Width     21.43      10.71    2.00    0.045 *</span></span>
<span><span class="co">## ---</span></span>
<span><span class="co">## Signif. codes:  </span></span>
<span><span class="co">## 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## (Dispersion parameter for binomial family taken to be 1)</span></span>
<span><span class="co">## </span></span>
<span><span class="co">##     Null deviance: 190.954  on 149  degrees of freedom</span></span>
<span><span class="co">## Residual deviance:  13.266  on 146  degrees of freedom</span></span>
<span><span class="co">## AIC: 21.27</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Number of Fisher Scoring iterations: 12</span></span></code></pre></div>
<p>The estimates (<span class="math inline">\(\beta_0, \beta_1,...\)</span> ) are
log-odds and can be converted into odds using <span class="math inline">\(exp(\beta)\)</span>.
A negative log-odds ratio means that the odds go down with an increase in
the value of the predictor. A predictor with a
positive log-odds ratio increases the odds. In this case, the odds of
looking at a Virginica iris goes down with Sepal.Width and increases with the
other two predictors.</p>
</div>
<div id="calculate-the-response" class="section level2" number="9.5">
<h2>
<span class="header-section-number">9.5</span> Calculate the Response<a class="anchor" aria-label="anchor" href="#calculate-the-response"><i class="fas fa-link"></i></a>
</h2>
<p><strong>Note:</strong> we do here in-sample testing on the data we learned the data
from. To get a generalization error estimate you should use a test set or
cross-validation!</p>
<div class="sourceCode" id="cb482"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">pr</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">model2</span>, <span class="va">x</span>, type<span class="op">=</span><span class="st">"response"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">pr</span>, <span class="fl">2</span><span class="op">)</span></span>
<span><span class="co">##  102  112    4   55   70   98  135    7   43  140   51   25 </span></span>
<span><span class="co">## 1.00 1.00 0.00 0.00 0.00 0.00 0.86 0.00 0.00 1.00 0.00 0.00 </span></span>
<span><span class="co">##    2   68  137   48   32   85   91  121   16  116   66  146 </span></span>
<span><span class="co">## 0.00 0.00 1.00 0.00 0.00 0.00 0.00 1.00 0.00 1.00 0.00 1.00 </span></span>
<span><span class="co">##   93   45   30  124  126   87   95   97  120   29   92   31 </span></span>
<span><span class="co">## 0.00 0.00 0.00 0.98 1.00 0.00 0.00 0.00 0.93 0.00 0.00 0.00 </span></span>
<span><span class="co">##   54   41  105  113   24  142  143   63   65    9  150   20 </span></span>
<span><span class="co">## 0.00 0.00 1.00 1.00 0.00 1.00 1.00 0.00 0.00 0.00 0.96 0.00 </span></span>
<span><span class="co">##   14   78   88    3   36   27   46   59   96   69   47  147 </span></span>
<span><span class="co">## 0.00 0.54 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.20 0.00 1.00 </span></span>
<span><span class="co">##  129  136   12  141  130   56   22   82   53   99    5   44 </span></span>
<span><span class="co">## 1.00 1.00 0.00 1.00 0.99 0.00 0.00 0.00 0.00 0.00 0.00 0.00 </span></span>
<span><span class="co">##   28   52  139   42   15   57   75   37   26  110  100  149 </span></span>
<span><span class="co">## 0.00 0.00 0.67 0.00 0.00 0.00 0.00 0.00 0.00 1.00 0.00 1.00 </span></span>
<span><span class="co">##  132  107   35   58  127  111  144   86  114   71  123  119 </span></span>
<span><span class="co">## 1.00 0.60 0.00 0.00 0.92 1.00 1.00 0.00 1.00 0.28 1.00 1.00 </span></span>
<span><span class="co">##   18    8  128   83  138   19  115   23   89   62   80  104 </span></span>
<span><span class="co">## 0.00 0.00 0.82 0.00 1.00 0.00 1.00 0.00 0.00 0.00 0.00 1.00 </span></span>
<span><span class="co">##   40   17   94  133   60   81  118  125  122   49  148   61 </span></span>
<span><span class="co">## 0.00 0.00 0.00 1.00 0.00 0.00 1.00 1.00 1.00 0.00 1.00 0.00 </span></span>
<span><span class="co">##   10  109  106   72   13   77   79   39  134   84   67  117 </span></span>
<span><span class="co">## 0.00 1.00 1.00 0.00 0.00 0.00 0.00 0.00 0.16 0.79 0.00 1.00 </span></span>
<span><span class="co">##  108  101  103   76    1   50  131   90   34   38    6   64 </span></span>
<span><span class="co">## 1.00 1.00 1.00 0.00 0.00 0.00 1.00 0.00 0.00 0.00 0.00 0.00 </span></span>
<span><span class="co">##   33  145   74   11   21   73 </span></span>
<span><span class="co">## 0.00 1.00 0.00 0.00 0.00 0.32</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span><span class="op">(</span><span class="va">pr</span>, breaks<span class="op">=</span><span class="fl">20</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span><span class="op">(</span><span class="va">pr</span><span class="op">[</span><span class="va">x</span><span class="op">$</span><span class="va">virginica</span><span class="op">==</span><span class="cn">TRUE</span><span class="op">]</span>, col<span class="op">=</span><span class="st">"red"</span>, breaks<span class="op">=</span><span class="fl">20</span>, add<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="R-Companion-Data-Mining_files/figure-html/unnamed-chunk-435-1.png" width="672"></div>
</div>
<div id="check-classification-performance" class="section level2" number="9.6">
<h2>
<span class="header-section-number">9.6</span> Check Classification Performance<a class="anchor" aria-label="anchor" href="#check-classification-performance"><i class="fas fa-link"></i></a>
</h2>
<p>We calculate the predicted class by checking if the probability is larger than
.5.</p>
<div class="sourceCode" id="cb483"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">pred</span> <span class="op">&lt;-</span> <span class="va">pr</span> <span class="op">&gt;</span> <span class="fl">.5</span></span></code></pre></div>
<p>Now er can create a confusion table and calculate the accuracy.</p>
<div class="sourceCode" id="cb484"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tbl</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span>actual <span class="op">=</span> <span class="va">x</span><span class="op">$</span><span class="va">virginica</span>, predicted <span class="op">=</span> <span class="va">pr</span><span class="op">&gt;</span><span class="fl">.5</span><span class="op">)</span></span>
<span><span class="va">tbl</span></span>
<span><span class="co">##        predicted</span></span>
<span><span class="co">## actual  FALSE TRUE</span></span>
<span><span class="co">##   FALSE    98    2</span></span>
<span><span class="co">##   TRUE      1   49</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/diag.html">diag</a></span><span class="op">(</span><span class="va">tbl</span><span class="op">)</span><span class="op">)</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">tbl</span><span class="op">)</span></span>
<span><span class="co">## [1] 0.98</span></span></code></pre></div>
<p>We can also use caret’s more advanced function <code><a href="https://rdrr.io/pkg/caret/man/confusionMatrix.html">confusionMatrix()</a></code>. Our code
above uses <code>logical</code> vectors.
but foo caret, we need to make sure that both, the reference and the predictions
are coded as <code>factor</code>.</p>
<div class="sourceCode" id="cb485"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">caret</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/caret/man/confusionMatrix.html">confusionMatrix</a></span><span class="op">(</span></span>
<span>  reference <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">x</span><span class="op">$</span><span class="va">virginica</span>, levels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="cn">TRUE</span>, <span class="cn">FALSE</span><span class="op">)</span><span class="op">)</span>, </span>
<span>  data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">pr</span><span class="op">&gt;</span><span class="fl">.5</span>, levels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="cn">TRUE</span>, <span class="cn">FALSE</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">## Confusion Matrix and Statistics</span></span>
<span><span class="co">## </span></span>
<span><span class="co">##           Reference</span></span>
<span><span class="co">## Prediction TRUE FALSE</span></span>
<span><span class="co">##      TRUE    49     2</span></span>
<span><span class="co">##      FALSE    1    98</span></span>
<span><span class="co">##                                         </span></span>
<span><span class="co">##                Accuracy : 0.98          </span></span>
<span><span class="co">##                  95% CI : (0.943, 0.996)</span></span>
<span><span class="co">##     No Information Rate : 0.667         </span></span>
<span><span class="co">##     P-Value [Acc &gt; NIR] : &lt;2e-16        </span></span>
<span><span class="co">##                                         </span></span>
<span><span class="co">##                   Kappa : 0.955         </span></span>
<span><span class="co">##                                         </span></span>
<span><span class="co">##  Mcnemar's Test P-Value : 1             </span></span>
<span><span class="co">##                                         </span></span>
<span><span class="co">##             Sensitivity : 0.980         </span></span>
<span><span class="co">##             Specificity : 0.980         </span></span>
<span><span class="co">##          Pos Pred Value : 0.961         </span></span>
<span><span class="co">##          Neg Pred Value : 0.990         </span></span>
<span><span class="co">##              Prevalence : 0.333         </span></span>
<span><span class="co">##          Detection Rate : 0.327         </span></span>
<span><span class="co">##    Detection Prevalence : 0.340         </span></span>
<span><span class="co">##       Balanced Accuracy : 0.980         </span></span>
<span><span class="co">##                                         </span></span>
<span><span class="co">##        'Positive' Class : TRUE          </span></span>
<span><span class="co">## </span></span></code></pre></div>
<p>We see that the model performs well with a very high accuracy and kappa value.</p>
</div>
<div id="regularized-logistic-regression" class="section level2" number="9.7">
<h2>
<span class="header-section-number">9.7</span> Regularized Logistic Regression<a class="anchor" aria-label="anchor" href="#regularized-logistic-regression"><i class="fas fa-link"></i></a>
</h2>
<p>Glmnet fits generalized linear models (including logistic regression)
using regularization via penalized maximum likelihood.
The regularization parameter <span class="math inline">\(\lambda\)</span> is a hyperparameter and
glmnet can use cross-validation to find an appropriate
value. glmnet does not have a function interface, so we have
to supply a matrix for <code>X</code> and a vector of responses for <code>y</code>.</p>
<div class="sourceCode" id="cb486"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://glmnet.stanford.edu">glmnet</a></span><span class="op">)</span></span>
<span><span class="co">## Loaded glmnet 4.1-8</span></span>
<span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/proxy/man/dist.html">as.matrix</a></span><span class="op">(</span><span class="va">x</span><span class="op">[</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">5</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="va">x</span><span class="op">$</span><span class="va">virginica</span></span>
<span></span>
<span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html">cv.glmnet</a></span><span class="op">(</span><span class="va">X</span>, <span class="va">y</span>, family <span class="op">=</span> <span class="st">"binomial"</span><span class="op">)</span></span>
<span><span class="va">fit</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Call:  cv.glmnet(x = X, y = y, family = "binomial") </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Measure: Binomial Deviance </span></span>
<span><span class="co">## </span></span>
<span><span class="co">##      Lambda Index Measure     SE Nonzero</span></span>
<span><span class="co">## min 0.00164    59   0.126 0.0456       5</span></span>
<span><span class="co">## 1se 0.00664    44   0.167 0.0422       3</span></span></code></pre></div>
<p>There are several selection rules for lambda, we look at the
coefficients of the logistic regression using the
lambda that gives the most regularized model such that the cross-validated error is within one standard error of the minimum cross-validated error.</p>
<div class="sourceCode" id="cb487"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">fit</span>, s <span class="op">=</span> <span class="va">fit</span><span class="op">$</span><span class="va">lambda.1se</span><span class="op">)</span></span>
<span><span class="co">## 6 x 1 sparse Matrix of class "dgCMatrix"</span></span>
<span><span class="co">##                   s1</span></span>
<span><span class="co">## (Intercept)  -16.961</span></span>
<span><span class="co">## Sepal.Length   .    </span></span>
<span><span class="co">## Sepal.Width   -1.766</span></span>
<span><span class="co">## Petal.Length   2.197</span></span>
<span><span class="co">## Petal.Width    6.820</span></span>
<span><span class="co">## useless        .</span></span></code></pre></div>
<p>A dot means 0. We see that the predictors Sepal.Length and
useless are not used in the prediction giving a models similar to
stepwise variable selection above.</p>
<p>A predict function is provided. We need to specify
what regularization to use and that we want to predict a class
label.</p>
<div class="sourceCode" id="cb488"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">fit</span>, newx <span class="op">=</span> <span class="va">X</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span>,<span class="op">]</span>, s <span class="op">=</span> <span class="va">fit</span><span class="op">$</span><span class="va">lambda.1se</span>, type <span class="op">=</span> <span class="st">"class"</span><span class="op">)</span></span>
<span><span class="co">##     s1     </span></span>
<span><span class="co">## 102 "TRUE" </span></span>
<span><span class="co">## 112 "TRUE" </span></span>
<span><span class="co">## 4   "FALSE"</span></span>
<span><span class="co">## 55  "FALSE"</span></span>
<span><span class="co">## 70  "FALSE"</span></span></code></pre></div>
<p>Glmnet provides supports many types of
generalized linear models. Examples can be found in the
article <a href="https://glmnet.stanford.edu/articles/glmnet.html">An Introduction to glmnet</a>.</p>
</div>
<div id="exercises-6" class="section level2" number="9.8">
<h2>
<span class="header-section-number">9.8</span> Exercises<a class="anchor" aria-label="anchor" href="#exercises-6"><i class="fas fa-link"></i></a>
</h2>
<p>We will again use the Palmer penguin data for the exercises.</p>
<div class="sourceCode" id="cb489"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://allisonhorst.github.io/palmerpenguins/">palmerpenguins</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">penguins</span><span class="op">)</span></span>
<span><span class="co">## # A tibble: 6 × 8</span></span>
<span><span class="co">##   species island    bill_length_mm bill_depth_mm</span></span>
<span><span class="co">##   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;</span></span>
<span><span class="co">## 1 Adelie  Torgersen           39.1          18.7</span></span>
<span><span class="co">## 2 Adelie  Torgersen           39.5          17.4</span></span>
<span><span class="co">## 3 Adelie  Torgersen           40.3          18  </span></span>
<span><span class="co">## 4 Adelie  Torgersen           NA            NA  </span></span>
<span><span class="co">## 5 Adelie  Torgersen           36.7          19.3</span></span>
<span><span class="co">## 6 Adelie  Torgersen           39.3          20.6</span></span>
<span><span class="co">## # ℹ 4 more variables: flipper_length_mm &lt;dbl&gt;,</span></span>
<span><span class="co">## #   body_mass_g &lt;dbl&gt;, sex &lt;chr&gt;, year &lt;dbl&gt;</span></span></code></pre></div>
<p>Create an R markdown document that performs the following:</p>
<ol style="list-style-type: decimal">
<li>Create a test and a training data set (see section <a href="classification-basic-concepts.html#holdout-method">Holdout Method</a> in Chapter 3).</li>
<li>Create a logistic regression using the training set to predict the variable sex.</li>
<li>Use stepwise variable selection. What variables are selected?</li>
<li>What do the parameters for for each of the selected features tell you?</li>
<li>Predict the sex of the penguins in the test set. Create a
confusion table and calculate the accuracy and discuss how well the model works.</li>
</ol>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="regression.html"><span class="header-section-number">8</span> Regression*</a></div>
<div class="next"><a href="references.html">References</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li>
<a class="nav-link" href="#logistic-regression-1"><span class="header-section-number">9</span> Logistic Regression*</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#packages-used-in-this-chapter-7">Packages Used in this Chapter</a></li></ul>
</li>
<li><a class="nav-link" href="#introduction-2"><span class="header-section-number">9.1</span> Introduction</a></li>
<li><a class="nav-link" href="#data-preparation-1"><span class="header-section-number">9.2</span> Data Preparation</a></li>
<li><a class="nav-link" href="#create-a-logistic-regression-model"><span class="header-section-number">9.3</span> Create a Logistic Regression Model</a></li>
<li><a class="nav-link" href="#stepwise-variable-selection-1"><span class="header-section-number">9.4</span> Stepwise Variable Selection</a></li>
<li><a class="nav-link" href="#calculate-the-response"><span class="header-section-number">9.5</span> Calculate the Response</a></li>
<li><a class="nav-link" href="#check-classification-performance"><span class="header-section-number">9.6</span> Check Classification Performance</a></li>
<li><a class="nav-link" href="#regularized-logistic-regression"><span class="header-section-number">9.7</span> Regularized Logistic Regression</a></li>
<li><a class="nav-link" href="#exercises-6"><span class="header-section-number">9.8</span> Exercises</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/mhahsler/Introduction_to_Data_Mining_R_Examples/blob/master/book_src/92_logistic_regression.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/mhahsler/Introduction_to_Data_Mining_R_Examples/edit/master/book_src/92_logistic_regression.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>An R Companion for Introduction to Data Mining</strong>" was written by Michael Hahsler. It was last built on 2024-11-15.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
